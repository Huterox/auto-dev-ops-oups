"""
@FileNameï¼šhomeHandler.py
@Authorï¼šHuterox
@Descriptionï¼šGo For It
@Timeï¼š2024/7/20 17:36
@Copyrightï¼šÂ©2018-2024 awesome!
"""
import os
import time

import toml
from openai import OpenAI
from base import current_dir_root
import streamlit_antd_components as sac


def home_assistant(st,doc,config):
    messages = st.container(height=470)
    if "messages" not in st.session_state:
        st.session_state["messages"] = [
            {"role": "assistant", "content": "æˆ‘æ˜¯æœ¬é¡¹ç›®çš„AIå°åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„ä¹ˆ?"}]

    for msg in st.session_state.messages:
        messages.chat_message(msg["role"]).write(msg["content"])

    default_key = config["DEFAULT"]["default_key"]
    default_base = config["DEFAULT"]["default_base"]
    default_model = config["DEFAULT"]["default_model"]
    default_temperature = config["DEFAULT"]["default_temperature"]
    if(default_base!=None and default_model!=""):
        placeholder = "æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„ä¹ˆï¼ŸğŸ˜€"
    else:
        placeholder = "æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„ä¹ˆï¼ŸğŸ˜€(è¯·å…ˆè®¾ç½®é»˜è®¤å¤§æ¨¡å‹KEY)"
    if prompt := st.chat_input(placeholder=placeholder):
        client = OpenAI(api_key=default_key,
                        base_url=default_base,
                        )
        st.session_state.messages.append({"role": "user", "content": prompt})
        messages.chat_message("user").write(prompt)
        try:
            response = client.chat.completions.create(
                model=default_model,
                temperature=default_temperature,
                messages=[
                    {"role": "system",
                     "content": "ä½ æ˜¯ä¸€ä¸ªåŸºäºä¸‹é¢å†…å®¹çš„AIå°åŠ©æ‰‹ï¼Œè¯·åŸºäºä¸‹é¢çš„å†…å®¹å’Œè‡ªå·±çš„çŸ¥è¯†å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n" + doc},
                    {"role": "user", "content": prompt}
                ])
            msg = response.choices[0].message.content
            st.session_state.messages.append({"role": "assistant", "content": msg})
        except Exception as e:
            msg = "æŠ±æ­‰ï¼Œå‡ºç°å¼‚å¸¸ï¼Œè¯·ç¨åå†è¯•~"
        with messages.chat_message("assistant"):
            placeholder = st.empty()
            full_response = ''
            for item in msg:
                full_response += item
                time.sleep(0.01)
                placeholder.markdown(full_response)
            placeholder.markdown(full_response)
        # messages.chat_message("assistant").write_stream(msg)


def home_settings(st,config):
    load_config_in_state(st, config)
    st.write("##### æ¨¡å‹é…ç½®")
    st.write("")
    col1, col2 = st.columns([0.6, 0.4], gap="large")
    with col1:
        area = st.container(height=450)
        # å¯¹ç›¸å…³çš„APIè¿›è¡Œè®¾ç½®ï¼ˆè®¾ç½®å·²ç»ç»‘å®šäº†å¯¹åº”çš„st.session_stateï¼‰
        # è¿™é‡Œé»˜è®¤ä½¿ç”¨çš„æ˜¯ OpenAI çš„æ¨¡å‹ï¼ˆè¿™é‡Œä½¿ç”¨çš„æ˜¯ä¸­è½¬ç«™ï¼‰
        area.write('''##### ```å®˜ç½‘ï¼šhttps://openai.com/```''')
        area.write('')
        new_openai_key = area.text_input("**API-KEYï¼š**", st.session_state.default_key)
        area.write('')
        new_openai_base = area.text_input("**API-BASEï¼š**", st.session_state.default_base)
        st.session_state.default_key = new_openai_key
        st.session_state.default_base = new_openai_base
        area.write('')
        new_temperature = area.slider("**Temperatureï¼š**", min_value=0.0, max_value=1.0, step=0.1,
                                      value=st.session_state.default_temperature)
        st.session_state.default_temperature = new_temperature

    with col2:
        area2 = st.container(height=450)
        with area2:
            default_mode =  config["DEFAULT"]["default_model"]
            model_list = ['gpt-4o-mini','gpt-4o','gpt-4-0125-preview',
                          'gpt-4-32k','gpt-4-0613','gpt-3.5-turbo','gpt-3.5-turbo-instruct'
                          ,'gpt-3.5-turbo-16k'
                          ]

            default_model = sac.segmented(
                items=[
                    sac.SegmentedItem(label=model_name) for model_name in model_list
                ], label='æ¨¡å‹é€‰æ‹©',
                align='center', direction="vertical", radius='lg',
                use_container_width=True,index=model_list.index(default_mode)
            )
            st.session_state.default_model = default_model
    st.write("")
    if st.button('ä¿å­˜', use_container_width=True, type="primary"):
        save_config_in_state(st, config)


def load_config_in_state(st, config):

    default_key = config["DEFAULT"]["default_key"]
    default_base = config["DEFAULT"]["default_base"]
    default_model = config["DEFAULT"]["default_model"]
    default_temperature = config["DEFAULT"]["default_temperature"]
    st.session_state.default_key = default_key
    st.session_state.default_base = default_base
    st.session_state.default_model = default_model
    st.session_state.default_temperature = default_temperature


def save_config_in_state(st,config):
    config["DEFAULT"]["default_key"] = st.session_state.default_key
    config["DEFAULT"]["default_base"] = st.session_state.default_base
    config["DEFAULT"]["default_model"] = st.session_state.default_model
    config["DEFAULT"]["default_temperature"] = st.session_state.default_temperature
    with open(os.path.join(current_dir_root, "api.toml"), 'w', encoding='utf-8') as file:
        toml.dump(config, file)
    st.toast("ä¿å­˜æˆåŠŸï¼", icon=":material/task_alt:")